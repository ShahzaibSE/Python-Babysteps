{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Prepare dataset & create baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2   3      4      5     6       7   8      9     10  \\\n",
       "0    0.00632  18.0   2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1    0.02731   0.0   7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2    0.02729   0.0   7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3    0.03237   0.0   2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4    0.06905   0.0   2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "..       ...   ...    ...  ..    ...    ...   ...     ...  ..    ...   ...   \n",
       "501  0.06263   0.0  11.93   0  0.573  6.593  69.1  2.4786   1  273.0  21.0   \n",
       "502  0.04527   0.0  11.93   0  0.573  6.120  76.7  2.2875   1  273.0  21.0   \n",
       "503  0.06076   0.0  11.93   0  0.573  6.976  91.0  2.1675   1  273.0  21.0   \n",
       "504  0.10959   0.0  11.93   0  0.573  6.794  89.3  2.3889   1  273.0  21.0   \n",
       "505  0.04741   0.0  11.93   0  0.573  6.030  80.8  2.5050   1  273.0  21.0   \n",
       "\n",
       "         11    12    13  \n",
       "0    396.90  4.98  24.0  \n",
       "1    396.90  9.14  21.6  \n",
       "2    392.83  4.03  34.7  \n",
       "3    394.63  2.94  33.4  \n",
       "4    396.90  5.33  36.2  \n",
       "..      ...   ...   ...  \n",
       "501  391.99  9.67  22.4  \n",
       "502  396.90  9.08  20.6  \n",
       "503  396.90  5.64  23.9  \n",
       "504  393.45  6.48  22.0  \n",
       "505  396.90  7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset = pd.read_csv('./housing.csv', header=None, delim_whitespace=True)\n",
    "house_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2   3      4      5     6       7   8      9     10  \\\n",
       "0  0.00632  18.0  2.31   0  0.538  6.575  65.2  4.0900   1  296.0  15.3   \n",
       "1  0.02731   0.0  7.07   0  0.469  6.421  78.9  4.9671   2  242.0  17.8   \n",
       "2  0.02729   0.0  7.07   0  0.469  7.185  61.1  4.9671   2  242.0  17.8   \n",
       "3  0.03237   0.0  2.18   0  0.458  6.998  45.8  6.0622   3  222.0  18.7   \n",
       "4  0.06905   0.0  2.18   0  0.458  7.147  54.2  6.0622   3  222.0  18.7   \n",
       "\n",
       "       11    12    13  \n",
       "0  396.90  4.98  24.0  \n",
       "1  396.90  9.14  21.6  \n",
       "2  392.83  4.03  34.7  \n",
       "3  394.63  2.94  33.4  \n",
       "4  396.90  5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_dataset.iloc[:,0:13]\n",
    "Y = house_dataset.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: -40.35 (31.98) MSE\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Modeling The Standardized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -20.45 (25.99) MSE\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2 - use a Sigmoid or similar activation function on the output layer to narrow output predictions to the same range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized: -555.61 (278.94) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=new_baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Standardized: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Tune The Neural Network Topology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.1 - Evaluate a Deeper Network Topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(6,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: -20.75 (23.03) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=larger_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Larger: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.2. Evaluate a Wider Network Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wider_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(20,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -25.86 (35.25) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=wider_model, epochs=100, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Really Scaling up: developing a model that overfits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(30,activation='relu'))\n",
    "    model.add(Dense(30,activation='relu'))\n",
    "    model.add(Dense(20,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wider: -35.31 (36.44) MSE\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=overfit_model, epochs=150, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "print(\"Wider: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Result: Standardized: -20.45 (25.99) MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Rewriting the code using the Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def functional_api():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13,activation='relu',input_shape=(13,)))\n",
    "    model.add(Dense(13,activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    # Compile.\n",
    "    model.compile(loss='MSE',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 9042.45% (28734.78%)\n"
     ]
    }
   ],
   "source": [
    "model = functional_api()\n",
    "history = model.fit(X,Y,epochs=50, batch_size=5, verbose=False)\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['loss']\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (np.mean(acc_values)*100, np.std(acc_values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8. Rewriting the code by doing Model Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel,self).__init__()\n",
    "        self.dense1 = Dense(13,activation='relu')\n",
    "        self.dense2 = Dense(13,activation='relu')\n",
    "        self.dense3 = Dense(1)\n",
    "    \n",
    "    def call(self,inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.dense3(x)\n",
    "\n",
    "def subclass_model():\n",
    "    inputs = tf.keras.Input(shape=(13,))\n",
    "    mymodel = MyModel()\n",
    "    outputs = mymodel.call(inputs)\n",
    "    # Keras Model.\n",
    "    model = tf.keras.Model(inputs,outputs)\n",
    "    # Compile.\n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 506 samples\n",
      "Epoch 1/50\n",
      "506/506 [==============================] - 1s 3ms/sample - loss: 3445.8009 - acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "506/506 [==============================] - 0s 726us/sample - loss: 78.7925 - acc: 0.0000e+00\n",
      "Epoch 3/50\n",
      "506/506 [==============================] - 0s 726us/sample - loss: 69.2261 - acc: 0.0000e+00\n",
      "Epoch 4/50\n",
      "506/506 [==============================] - 0s 729us/sample - loss: 66.4463 - acc: 0.0000e+00\n",
      "Epoch 5/50\n",
      "506/506 [==============================] - 0s 720us/sample - loss: 64.6422 - acc: 0.0000e+00\n",
      "Epoch 6/50\n",
      "506/506 [==============================] - 0s 728us/sample - loss: 62.5616 - acc: 0.0000e+00\n",
      "Epoch 7/50\n",
      "506/506 [==============================] - 0s 716us/sample - loss: 60.9100 - acc: 0.0000e+00\n",
      "Epoch 8/50\n",
      "506/506 [==============================] - 0s 721us/sample - loss: 61.1684 - acc: 0.0000e+00\n",
      "Epoch 9/50\n",
      "506/506 [==============================] - 0s 732us/sample - loss: 61.1911 - acc: 0.0000e+00\n",
      "Epoch 10/50\n",
      "506/506 [==============================] - 0s 733us/sample - loss: 59.4518 - acc: 0.0000e+00\n",
      "Epoch 11/50\n",
      "506/506 [==============================] - 0s 719us/sample - loss: 58.5887 - acc: 0.0000e+00\n",
      "Epoch 12/50\n",
      "506/506 [==============================] - 0s 731us/sample - loss: 56.8640 - acc: 0.0000e+00\n",
      "Epoch 13/50\n",
      "506/506 [==============================] - 0s 734us/sample - loss: 56.3078 - acc: 0.0000e+00\n",
      "Epoch 14/50\n",
      "506/506 [==============================] - 0s 737us/sample - loss: 56.0460 - acc: 0.0000e+00\n",
      "Epoch 15/50\n",
      "506/506 [==============================] - 0s 719us/sample - loss: 55.6279 - acc: 0.0000e+00\n",
      "Epoch 16/50\n",
      "506/506 [==============================] - 0s 725us/sample - loss: 54.3910 - acc: 0.0000e+00\n",
      "Epoch 17/50\n",
      "506/506 [==============================] - 0s 729us/sample - loss: 53.2859 - acc: 0.0000e+00\n",
      "Epoch 18/50\n",
      "506/506 [==============================] - 0s 732us/sample - loss: 52.2388 - acc: 0.0000e+00\n",
      "Epoch 19/50\n",
      "506/506 [==============================] - 0s 745us/sample - loss: 51.3212 - acc: 0.0000e+00\n",
      "Epoch 20/50\n",
      "506/506 [==============================] - 0s 754us/sample - loss: 51.8794 - acc: 0.0000e+00\n",
      "Epoch 21/50\n",
      "506/506 [==============================] - 0s 712us/sample - loss: 52.0286 - acc: 0.0000e+00\n",
      "Epoch 22/50\n",
      "506/506 [==============================] - 0s 723us/sample - loss: 49.9550 - acc: 0.0000e+00\n",
      "Epoch 23/50\n",
      "506/506 [==============================] - 0s 735us/sample - loss: 49.5964 - acc: 0.0000e+00\n",
      "Epoch 24/50\n",
      "506/506 [==============================] - 0s 724us/sample - loss: 49.9704 - acc: 0.0000e+00\n",
      "Epoch 25/50\n",
      "506/506 [==============================] - 0s 736us/sample - loss: 49.4794 - acc: 0.0000e+00\n",
      "Epoch 26/50\n",
      "506/506 [==============================] - 0s 724us/sample - loss: 47.0583 - acc: 0.0000e+00\n",
      "Epoch 27/50\n",
      "506/506 [==============================] - 0s 728us/sample - loss: 46.2504 - acc: 0.0000e+00\n",
      "Epoch 28/50\n",
      "506/506 [==============================] - 0s 732us/sample - loss: 47.1011 - acc: 0.0000e+00\n",
      "Epoch 29/50\n",
      "506/506 [==============================] - 0s 718us/sample - loss: 44.3835 - acc: 0.0000e+00\n",
      "Epoch 30/50\n",
      "506/506 [==============================] - 0s 714us/sample - loss: 44.7182 - acc: 0.0000e+00\n",
      "Epoch 31/50\n",
      "506/506 [==============================] - 0s 730us/sample - loss: 45.4999 - acc: 0.0000e+00\n",
      "Epoch 32/50\n",
      "506/506 [==============================] - 0s 742us/sample - loss: 46.9873 - acc: 0.0000e+00\n",
      "Epoch 33/50\n",
      "506/506 [==============================] - 0s 726us/sample - loss: 42.2465 - acc: 0.0000e+00\n",
      "Epoch 34/50\n",
      "506/506 [==============================] - 0s 736us/sample - loss: 41.5148 - acc: 0.0000e+00\n",
      "Epoch 35/50\n",
      "506/506 [==============================] - 0s 716us/sample - loss: 39.6373 - acc: 0.0000e+00\n",
      "Epoch 36/50\n",
      "506/506 [==============================] - 0s 726us/sample - loss: 40.3814 - acc: 0.0000e+00\n",
      "Epoch 37/50\n",
      "506/506 [==============================] - 0s 730us/sample - loss: 39.1713 - acc: 0.0000e+00\n",
      "Epoch 38/50\n",
      "506/506 [==============================] - 0s 725us/sample - loss: 43.8693 - acc: 0.0000e+00\n",
      "Epoch 39/50\n",
      "506/506 [==============================] - 0s 723us/sample - loss: 39.6444 - acc: 0.0000e+00\n",
      "Epoch 40/50\n",
      "506/506 [==============================] - 0s 725us/sample - loss: 40.1108 - acc: 0.0000e+00\n",
      "Epoch 41/50\n",
      "506/506 [==============================] - 0s 725us/sample - loss: 36.8657 - acc: 0.0000e+00\n",
      "Epoch 42/50\n",
      "506/506 [==============================] - 0s 723us/sample - loss: 36.6075 - acc: 0.0000e+00\n",
      "Epoch 43/50\n",
      "506/506 [==============================] - 0s 730us/sample - loss: 40.2161 - acc: 0.0000e+00\n",
      "Epoch 44/50\n",
      "506/506 [==============================] - 0s 730us/sample - loss: 35.9903 - acc: 0.0000e+00\n",
      "Epoch 45/50\n",
      "506/506 [==============================] - 0s 744us/sample - loss: 35.9994 - acc: 0.0000e+00\n",
      "Epoch 46/50\n",
      "506/506 [==============================] - 0s 740us/sample - loss: 37.8871 - acc: 0.0000e+00\n",
      "Epoch 47/50\n",
      "506/506 [==============================] - 0s 730us/sample - loss: 36.7577 - acc: 0.0000e+00\n",
      "Epoch 48/50\n",
      "506/506 [==============================] - 0s 731us/sample - loss: 37.9391 - acc: 0.0000e+00\n",
      "Epoch 49/50\n",
      "506/506 [==============================] - 0s 728us/sample - loss: 34.5526 - acc: 0.0000e+00\n",
      "Epoch 50/50\n",
      "506/506 [==============================] - 0s 733us/sample - loss: 34.4146 - acc: 0.0000e+00\n",
      "Result: 11687.15% (47566.90%)\n"
     ]
    }
   ],
   "source": [
    "mymodel = subclass_model()\n",
    "history = mymodel.fit(X,Y,epochs=50, batch_size=5, verbose=True)\n",
    "history_dict = history.history\n",
    "acc_values = history_dict['loss']\n",
    "print(\"Result: %.2f%% (%.2f%%)\" % (np.mean(acc_values)*100, np.std(acc_values)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9. Rewriting the code without using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "num_val_samples = len(X) // k\n",
    "num_epochs = 50\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = Y[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "#     print(val_data,val_targets)\n",
    "#     partial_train_data =np.concatenate([X[:i * num_val_samples],X[(i + 1) * num_val_samples:]],axis=0)\n",
    "#     partial_train_targets =np.concatenate([Y[:i * num_val_samples],Y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    model = baseline_model()\n",
    "    model.fit(val_data, val_targets,epochs=num_epochs, batch_size=5, verbose=0)\n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"K-Fold Results: {str(np.mean(all_scores)*100)}%,{str(np.std(all_scores)*100)}%.\")\n",
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
